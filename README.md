# Dual-Path Lambda Learning  
### Functional Adaptive Convergence via Drift Minimization and Gain Control

This repository implements a **minimal functional learning system** that compares two fundamentally different optimization dynamics:

â€¢ Standard gradient drift minimization  
â€¢ Adaptive gain-controlled learning with internal sensitivity decay  

The system is built entirely from **immutable lambda-style state transitions**, turning learning into a clean dynamical process rather than imperative parameter mutation.

Convergence is evaluated using **information-theoretic drift (KL divergence)** alongside prediction error.

## The simulation demonstrates that adaptive gain learning preserves convergence speed while significantly reducing stochastic variance, producing smooth, repeatable, and noise-robust trajectories.

---

## ğŸ” Core Concept

Learning is modeled as a deterministic state machine:

Each update step:

1. Observes noisy data sampled from a true underlying distribution  
2. Computes an error signal relative to the current internal belief  
3. Applies pure functional transitions to produce the next state  

Two learning pathways operate in parallel:

### Path A â€” Drift Minimization

A classic gradient descent dynamic that directly adjusts the internal representation toward observed data.

### Path B â€” Adaptive Gain Control

A coupled system where:

â€¢ The representation is updated  
â€¢ A sensitivity (gain) parameter scales learning intensity  
â€¢ The gain decays over time, stabilizing convergence  

This creates a self-regulating learning process.

---

## ğŸ§  Functional Architecture

All learning behavior is expressed as stateless transformations:

â€¢ No in-place parameter mutation  
â€¢ No optimizer objects  
â€¢ No hidden side effects  

State evolution is entirely driven by composable transition functions.

This mirrors functional dynamical systems used in theoretical ML and neuromorphic models.

---

## ğŸ“Š What Is Measured

At every step the system tracks:

â€¢ Information drift between learned and true distributions  
â€¢ Prediction error on sampled data  
â€¢ Internal gain dynamics  

This directly measures **how accurately the model infers reality**, not just loss reduction.

---

## ğŸ”¬ Key Experimental Observations

Across runs, adaptive gain control consistently:

âœ… Converges faster  
âœ… Produces smoother learning curves  
âœ… Resists noise-induced oscillations  
âœ… Stabilizes long-term inference  

While drift-only learning overshoots and fluctuates under noise.

---

## ğŸ§ª Main Takeaways

### 1. Learning benefits from internal control dynamics

Coupling representation updates with a self-regulating sensitivity parameter dramatically improves stability.

---

### 2. Adaptive behavior emerges from simple rules

Second-order style optimization effects arise without complex math or heavy algorithms.

---

### 3. Information convergence matters more than loss alone

The system does not just minimize error â€” it actively aligns inferred structure with ground truth.

---

### 4. Functional state transitions are sufficient for learning systems

Complex learning behavior can emerge from pure transformations.

---

## ğŸ¯ Scientific Relevance

This project connects ideas from:

â€¢ Variational inference  
â€¢ Predictive coding  
â€¢ Adaptive optimization  
â€¢ Control-theoretic learning  
â€¢ Functional programming models of computation  

In a minimal, interpretable simulation.

---

## ğŸ“ˆ Visualization

A real-time GUI displays:

â€¢ Information drift comparison  
â€¢ Prediction error trajectories  
â€¢ Gain parameter decay  

Allowing intuitive inspection of learning dynamics.


